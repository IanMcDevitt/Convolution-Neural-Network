{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1H7yycSTGo/MHx1/6nBwO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IanMcDevitt/Convolution-Neural-Network/blob/main/lenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolution Neural Network on MNIST Dataset"
      ],
      "metadata": {
        "id": "M6gEEIuajZhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install opencv-contrib-python\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1qhU1ai0olO",
        "outputId": "05828445-b6e0-47e5-db9f-35bb0b50637e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "dTd6FzNEig1Z"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Module\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import MaxPool2d\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import LogSoftmax\n",
        "from io import BytesIO\n",
        "import io \n",
        "from typing import Any, BinaryIO, Callable, cast, Dict, Optional, Type, Tuple, Union, IO\n",
        "\n",
        "from torch import flatten\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# set the numpy seed for better reproducibility\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "# import the necessary packages\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "import argparse\n",
        "import imutils\n",
        "import torch\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a class numChannels, classes \n",
        "# numChannels = the number of channels to be used either 1 or 3 for gray scale or rgb\n",
        "#classes the number of classifing classes\n",
        "class LeNet(Module):\n",
        "  def __init__(self, numChannels, classes):\n",
        "    # call the parent constructor\n",
        "    super(LeNet, self).__init__()\n",
        "   \n",
        "\t\t# initialize first set of CONV => RELU => POOL layers\n",
        "    # produces out put images bightness value at a given pixel is the function of the weighted average brightness of surrounding pixels \n",
        "    # the size of these image outputs are 5x5 matrices \n",
        "\n",
        "    self.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
        "\t\t  kernel_size=(5, 5))\n",
        "    \n",
        "    # ReLu is the activation function\n",
        "    self.relu1 = ReLU()\n",
        "  \n",
        "    # max pool takes a 2x2 window of max values of the input and downsamples them\n",
        "    self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t# initialize second set of CONV => RELU => POOL layers\n",
        "    #  a second layer of convolution to take the output into input\n",
        "    self.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
        "\t\t\tkernel_size=(5, 5))\n",
        "    self.relu2 = ReLU()\n",
        "    self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\t\t# initialize first (and only) set of FC => RELU layers\n",
        "    self.fc1 = Linear(in_features=800, out_features=500)\n",
        "    self.relu3 = ReLU()\n",
        "\t\t# initialize our softmax classifier\n",
        "    # maps features too classes\n",
        "    self.fc2 = Linear(in_features=500, out_features=classes)\n",
        "    self.logSoftmax = LogSoftmax(dim=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "\t\t# pass the input through our first set of CONV => RELU =>\n",
        "\t\t# POOL layers\n",
        "    x = self.conv1(x)\n",
        "    x = self.relu1(x)\n",
        "    x = self.maxpool1(x)\n",
        "\t\t# pass the output from the previous layer through the second\n",
        "\t\t# set of CONV => RELU => POOL layers\n",
        "    x = self.conv2(x)\n",
        "    x = self.relu2(x)\n",
        "    x = self.maxpool2(x)\n",
        "\t\t# flatten the output from the previous layer and pass it\n",
        "\t\t# through our only set of FC => RELU layers\n",
        "    x = flatten(x, 1)\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu3(x)\n",
        "\t\t# pass the output to our softmax classifier to get our output\n",
        "\t\t# predictions\n",
        "    x = self.fc2(x)\n",
        "    output = self.logSoftmax(x)\n",
        "\t\t# return the output predictions\n",
        "    return output\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "2GU3Ltx-iwBb"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
        "\thelp=\"path to output trained model\")\n",
        "ap.add_argument(\"-p\", \"--plot\", type=str, required=True,\n",
        "\thelp=\"path to output loss/accuracy plot\")\n",
        "args = vars(ap.parse_args())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "iLaSraDNr9-_",
        "outputId": "ef50a498-4da5-465f-d0f4-3391078320fe"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: ipykernel_launcher.py [-h] -m MODEL -p PLOT\n",
            "ipykernel_launcher.py: error: the following arguments are required: -m/--model, -p/--plot\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define training hyperparameters\n",
        "INIT_LR = 1e-3\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "# define the train and val splits\n",
        "TRAIN_SPLIT = 0.75\n",
        "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
        "# set the device we will be using to train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "21pds44R3xYI"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the KMNIST dataset\n",
        "print(\"[INFO] loading the MNIST dataset...\")\n",
        "trainData = MNIST(root=\"data\", train=True, download=True,\n",
        "\ttransform=ToTensor())\n",
        "testData = MNIST(root=\"data\", train=False, download=True,\n",
        "\ttransform=ToTensor())\n",
        "# calculate the train/validation split\n",
        "print(\"[INFO] generating the train/validation split...\")\n",
        "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
        "numValSamples = int(len(trainData) * VAL_SPLIT)\n",
        "(trainData, valData) = random_split(trainData,\n",
        "\t[numTrainSamples, numValSamples],\n",
        "\tgenerator=torch.Generator().manual_seed(42))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctfVX-V03ypm",
        "outputId": "55c55481-565e-4832-e472-96a9c9689e73"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading the MNIST dataset...\n",
            "[INFO] generating the train/validation split...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the train, validation, and test data loaders\n",
        "trainDataLoader = DataLoader(trainData, shuffle=True,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
        "testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n",
        "# calculate steps per epoch for training and validation set\n",
        "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
        "valSteps = len(valDataLoader.dataset) // BATCH_SIZE"
      ],
      "metadata": {
        "id": "LEwJNrDM3_AS"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the LeNet model\n",
        "print(\"[INFO] initializing the LeNet model...\")\n",
        "model = LeNet(\n",
        "\tnumChannels=1,\n",
        "\tclasses=len(trainData.dataset.classes)).to(device)\n",
        "# initialize our optimizer and loss function\n",
        "opt = Adam(model.parameters(), lr=INIT_LR)\n",
        "lossFn = nn.NLLLoss()\n",
        "# initialize a dictionary to store training history\n",
        "H = {\n",
        "\t\"train_loss\": [],\n",
        "\t\"train_acc\": [],\n",
        "\t\"val_loss\": [],\n",
        "\t\"val_acc\": []\n",
        "}\n",
        "# measure how long training is going to take\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AktjcwZr4Dt-",
        "outputId": "bcd7f67d-32c7-430e-b353-ee1b5104eede"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] initializing the LeNet model...\n",
            "[INFO] training the network...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over our epochs\n",
        "for e in range(0, EPOCHS):\n",
        "\t# set the model in training mode\n",
        "\tmodel.train()\n",
        "\t# initialize the total training and validation loss\n",
        "\ttotalTrainLoss = 0\n",
        "\ttotalValLoss = 0\n",
        "\t# initialize the number of correct predictions in the training\n",
        "\t# and validation step\n",
        "\ttrainCorrect = 0\n",
        "\tvalCorrect = 0\n",
        "\t# loop over the training set\n",
        "\tfor (x, y) in trainDataLoader:\n",
        "\t\t# send the input to the device\n",
        "\t\t(x, y) = (x.to(device), y.to(device))\n",
        "\t\t# perform a forward pass and calculate the training loss\n",
        "\t\tpred = model(x)\n",
        "\t\tloss = lossFn(pred, y)\n",
        "\t\t# zero out the gradients, perform the backpropagation step,\n",
        "\t\t# and update the weights\n",
        "\t\topt.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\topt.step()\n",
        "\t\t# add the loss to the total training loss so far and\n",
        "\t\t# calculate the number of correct predictions\n",
        "\t\ttotalTrainLoss += loss\n",
        "\t\ttrainCorrect += (pred.argmax(1) == y).type(\n",
        "\t\t\ttorch.float).sum().item()"
      ],
      "metadata": {
        "id": "oRNvMxZu4H6U"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# switch off autograd for evaluation\n",
        "with torch.no_grad():\n",
        "\t\t# set the model in evaluation mode\n",
        "\t\tmodel.eval()\n",
        "\t\t# loop over the validation set\n",
        "\t\tfor (x, y) in valDataLoader:\n",
        "\t\t\t# send the input to the device\n",
        "\t\t\t(x, y) = (x.to(device), y.to(device))\n",
        "\t\t\t# make the predictions and calculate the validation loss\n",
        "\t\t\tpred = model(x)\n",
        "\t\t\ttotalValLoss += lossFn(pred, y)\n",
        "\t\t\t# calculate the number of correct predictions\n",
        "\t\t\tvalCorrect += (pred.argmax(1) == y).type(\n",
        "\t\t\t\ttorch.float).sum().item()"
      ],
      "metadata": {
        "id": "yahlSaEM8y5M"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the average training and validation loss\n",
        "avgTrainLoss = totalTrainLoss / trainSteps\n",
        "avgValLoss = totalValLoss / valSteps\n",
        "\t# calculate the training and validation accuracy\n",
        "trainCorrect = trainCorrect / len(trainDataLoader.dataset)\n",
        "valCorrect = valCorrect / len(valDataLoader.dataset)\n",
        "\t# update our training history\n",
        "H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "H[\"train_acc\"].append(trainCorrect)\n",
        "H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
        "H[\"val_acc\"].append(valCorrect)\n",
        "\t# print the model training and validation information\n",
        "print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
        "print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
        "\t\tavgTrainLoss, trainCorrect))\n",
        "print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
        "\t\tavgValLoss, valCorrect))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d9RYfP085di",
        "outputId": "60bd1e96-9e9e-44dc-d1c4-1421206bb56d"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] EPOCH: 10/10\n",
            "Train loss: 0.008576, Train accuracy: 0.9972\n",
            "Val loss: 0.037830, Val accuracy: 0.9913\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# finish measuring how long training took\n",
        "endTime = time.time()\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
        "\tendTime - startTime))\n",
        "# we can now evaluate the network on the test set\n",
        "print(\"[INFO] evaluating network...\")\n",
        "# turn off autograd for testing evaluation\n",
        "with torch.no_grad():\n",
        "\t# set the model in evaluation mode\n",
        "\tmodel.eval()\n",
        "\t\n",
        "\t# initialize a list to store our predictions\n",
        "\tpreds = []\n",
        "\t# loop over the test set\n",
        "\tfor (x, y) in testDataLoader:\n",
        "\t\t# send the input to the device\n",
        "\t\tx = x.to(device)\n",
        "\t\t# make the predictions and add them to the list\n",
        "\t\tpred = model(x)\n",
        "\t\tpreds.extend(pred.argmax(axis=1).cpu().numpy())\n",
        "# generate a classification report\n",
        "print(classification_report(testData.targets.cpu().numpy(),\n",
        "\tnp.array(preds), target_names=testData.classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y25A7Ac29A1E",
        "outputId": "d08d0965-c7df-4667-e286-c0c7d09d7c14"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] total time taken to train the model: 499.16s\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    0 - zero       0.99      0.99      0.99       980\n",
            "     1 - one       0.99      1.00      0.99      1135\n",
            "     2 - two       0.99      0.99      0.99      1032\n",
            "   3 - three       0.99      1.00      0.99      1010\n",
            "    4 - four       0.99      0.99      0.99       982\n",
            "    5 - five       0.99      0.99      0.99       892\n",
            "     6 - six       0.99      0.99      0.99       958\n",
            "   7 - seven       0.99      0.99      0.99      1028\n",
            "   8 - eight       1.00      0.99      0.99       974\n",
            "    9 - nine       0.99      0.98      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "f = BytesIO()\n",
        "buffer = io.BytesIO()\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
        "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
        "plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "#plt.savefig(args[\"plot\"])\n",
        "plt.show()\n",
        "plt.savefig(f, format=\"svg\")\n",
        "# serialize the model to disk\n",
        "torch.save(model, buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lccj97bw9FRg",
        "outputId": "f547c199-adfa-4bd2-a648-2eb13e6a21bc"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the device we will be using to test the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# load the KMNIST dataset and randomly grab 10 data points\n",
        "print(\"[INFO] loading the KMNIST test dataset...\")\n",
        "testData = MNIST(root=\"data\", train=False, download=True,\n",
        "\ttransform=ToTensor())\n",
        "idxs = np.random.choice(range(0, len(testData)), size=(10,))\n",
        "testData = Subset(testData, idxs)\n",
        "# initialize the test data loader\n",
        "testDataLoader = DataLoader(testData, batch_size=1)\n",
        "# load the model and set it to evaluation mode\n",
        "#model = torch.load(buffer).to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj0ZktI2RHsd",
        "outputId": "8b1e638d-6ce3-4f75-df6b-b4bd4edf469e"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading the KMNIST test dataset...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
              "  (relu3): ReLU()\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              "  (logSoftmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# switch off autograd\n",
        "with torch.no_grad():\n",
        "\t# loop over the test set\n",
        "\tfor (image, label) in testDataLoader:\n",
        "\t\t# grab the original image and ground truth label\n",
        "\t\torigImage = image.numpy().squeeze(axis=(0, 1))\n",
        "\t\tgtLabel = testData.dataset.classes[label.numpy()[0]]\n",
        "\t\t# send the input to the device and make predictions on it\n",
        "\t\timage = image.to(device)\n",
        "\t\tpred = model(image)\n",
        "\t\t# find the class label index with the largest corresponding\n",
        "\t\t# probability\n",
        "\t\tidx = pred.argmax(axis=1).cpu().numpy()[0]\n",
        "\t\tpredLabel = testData.dataset.classes[idx]"
      ],
      "metadata": {
        "id": "DpUOrU-5T_RG"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the image from grayscale to RGB (so we can draw on\n",
        "\t\t# it) and resize it (so we can more easily see it on our\n",
        "\t\t# screen)\n",
        "origImage = np.dstack([origImage] * 3)\n",
        "origImage = imutils.resize(origImage, width=128)\n",
        "\t\t# draw the predicted class label on it\n",
        "color = (0, 255, 0) if gtLabel == predLabel else (0, 0, 255)\n",
        "cv2.putText(origImage, gtLabel, (2, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.95, color, 2)\n",
        "\t\t# display the result in terminal and show the input image\n",
        "print(\"[INFO] ground truth label: {}, predicted label: {}\".format(\n",
        "\t\t\tgtLabel, predLabel))\n",
        "cv2.imshow(\"image\", origImage)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "93D_vo8PUAek",
        "outputId": "ccbc23b3-f738-4e90-e9b8-394fcadc37a2"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-168-3bcfa789eead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0;31m# draw the predicted class label on it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgtLabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredLabel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgtLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0;31m# display the result in terminal and show the input image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m print(\"[INFO] ground truth label: {}, predicted label: {}\".format(\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/core/src/copy.cpp:71: error: (-215:Assertion failed) cn <= 4 in function 'scalarToRawData'\n"
          ]
        }
      ]
    }
  ]
}